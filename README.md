# ğŸ§  Digital Twin: Agentic RAG Personal Assistant

![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![LangChain](https://img.shields.io/badge/LangChain-Framework-green) ![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red) ![OpenAI](https://img.shields.io/badge/LLM-GPT--4o--Mini-orange)

A production-grade **Agentic RAG (Retrieval-Augmented Generation)** system that serves as a "Digital Twin." It autonomously decides whether to answer queries based on my personal local data (Resume, Projects, Codebase) or by searching the live internet.

## ğŸ¥ Visual Demo

> **"Mind decides. Body acts."**
> Watch how the Agentic Brain processes a user query in real-time vs. retrieving static memory.

*[watch the full architectural breakdown on LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7424666816813223937/?originTrackingId=dKu36J6UxoOKh2MaveFe1Q%3D%3D).*

---

## ğŸš€ Key Features

* **ğŸ•µï¸â€â™‚ï¸ Agentic Workflow (ReAct Pattern):**

  Unlike standard RAG chains, this system uses an Agent that reasons before acting. It dynamically selects tools based on user intent:
  * `search_my_files`: For questions about "Arati" (Resume, specific coding projects).
  * `duckduckgo_search`: For real-time queries (e.g., "Current Bitcoin price").
  * **Direct Answer**: For chit-chat or general knowledge.

* **ğŸ“‚ Multi-Modal "Universal Router":**

  Custom file ingestion that supports more than just PDFs. It automatically detects and routes:
  * `.pdf` (Resumes/Docs)
  * `".txt",
                    ".py",
                    ".sh",
                    ".md",
                    ".json",
                    ".log",
                    ".java",
                    ".c"` (Codebases)
  * `.csv` (Data spreadsheets)

* **ğŸ§  Persistent Memory:**

  Implements `FileChatMessageHistory` to remember context across conversation turns (e.g., "What was the last thing I asked you?").

* **ğŸ§¹ "Nuclear" Data Cleanup:**

  Automated protocol to flush and rebuild the Vector DB on restart, solving the "Ghost Data" issue where deleted files persisted in embeddings.

* **ğŸ›¡ï¸ Hallucination Control:**

  Engineered system prompts to prioritize local context over pre-trained knowledge.
---

## ğŸ› ï¸ Tech Stack

* **LLM:** GPT-4o-mini (via OpenAI API)
* **Orchestration:** LangChain (Python)
* **Vector Database:** ChromaDB (Local persistence)
* **Frontend:** Streamlit
* **Tools:** DuckDuckGo Search, PyPDF, Custom File Loaders

---

## ğŸ—ï¸ Architecture

The system follows a **ReAct (Reasoning + Acting)** loop:

1.  **Input:** User asks a question.
2.  **Thought:** The LLM analyzes the query to determine the required domain.
3.  **Action:**
    * If *Personal*, it queries the **ChromaDB** vector store.
    * If *External*, it queries **DuckDuckGo**.
4.  **Observation:** The tool returns raw data.
5.  **Final Answer:** The LLM synthesizes the data into a natural language response.

---

## âš™ï¸ Installation & Setup

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/AratiSankaliya12/digital-twin-agentic-rag.git
    cd digital-twin-agentic-rag
    ```

2.  **Create a Virtual Environment**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set Up Environment Variables**
    Create a `.env` file in the root directory and add your OpenAI API key:
    ```env
    OPENAI_API_KEY=your_sk_key_here
    ```

5.  **Run the Application**
    ```bash
    streamlit run app.py
    ```

---

## ğŸ“‚ Project Structure

This repository is organized into phases, mirroring my learning journey from basic experiments to a production microservice.

```text
â”œâ”€â”€ 00_The_Research_Lab/       # Phase 0: R&D
â”‚   â”œâ”€â”€ Memory_Experiments/    # Prototypes for Interactive vs Persistent Memory
â”‚   â””â”€â”€ RAG_Experiments/       # Evolution from Basic PDF RAG to Multi-Doc Routers
â”‚
â”œâ”€â”€ 01_The_Pipeline/           # Phase 1: The Core
â”‚   â””â”€â”€ main.py                # Basic RAG bot (Fixed "Ghost Data" & Hallucinations)
â”‚
â”œâ”€â”€ 02_The_Agent/              # Phase 2: The Brain
â”‚   â””â”€â”€ agent.py               # ReAct Agent with Tool Calling (File Search + DuckDuckGo)
â”‚
â”œâ”€â”€ 03_The_Interface/          # Phase 3: The Face
â”‚   â””â”€â”€ app.py                 # Streamlit Web App with Session State & Caching
â”‚
â”œâ”€â”€ 04_The_Production_API/     # Phase 4: The Microservice
â”‚   â”œâ”€â”€ server.py              # FastAPI Backend (REST API)
â”‚   â””â”€â”€ rag_core.py            # Decoupled Agent Logic
â”‚
â”œâ”€â”€ assets/                    # Screenshots & Demo Videos
â””â”€â”€ README.md                  # Documentation
```
---

## ğŸš§ Challenges & Solutions

[Click here!](https://github.com/AratiSankaliya12/digital-twin-agentic-rag/tree/main/Challenges%20%26%20Solutions)
